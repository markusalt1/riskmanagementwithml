{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.utils import shuffle\r\n",
    "from scipy import stats\r\n",
    "from scipy import optimize\r\n",
    "import joblib\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "#directory for saving results\r\n",
    "filepath = \".../Resultate_final/Put/IS/test/Put_GlueVaR_IS_2_test_saved/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Market and option parameters as in section 4.1 of 'Assessing Asset-Liability Risk with Neural Networks' (Cheridito, Ery, WÃ¼thrich 2020)\r\n",
    "s_0 = 100\r\n",
    "r = 0.01\r\n",
    "mu = 0.05\r\n",
    "sigma = 0.2\r\n",
    "tau = 1/52\r\n",
    "T = 1/3\r\n",
    "K = 100\r\n",
    "\r\n",
    "#quantile for which the IS distribution is computed\r\n",
    "alpha_IS = 0.975\r\n",
    "#Confidence levels and parameters for GlueVaR\r\n",
    "alpha_Glue = 0.95\r\n",
    "beta_Glue = 0.995\r\n",
    "omega_Glue = np.array([1/3,1/3])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Sizes for training set, validation set, test set, and set size for Monte Carlo estimation of the risk measures\r\n",
    "M_1 = 1500000\r\n",
    "M_2 = 500000\r\n",
    "M_3 = 500000\r\n",
    "#ignore N or N_2 in the following. Was kept just in case, but not used.\r\n",
    "N_2 = 1\r\n",
    "M_MC = 500000\r\n",
    "#size of the set of data points used to calculate an IS density\r\n",
    "M_IS = 2000000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Calculating simulated values of S_tau and simulated payoffs from standard normal random variable simulations\r\n",
    "def data_gen(Z,V):\r\n",
    "    #simulate S_tau under P\r\n",
    "    S_tau = s_0 * np.exp( (mu-0.5*sigma**2)*tau + sigma*np.sqrt(tau)*Z)\r\n",
    "    #Simulate S_T given S_tau under Q\r\n",
    "    S_T = S_tau * np.exp( (r-0.5*sigma**2)*(T-tau) + sigma*np.sqrt(T-tau)*V)\r\n",
    "    #Calculate corresponding simulated discounted payoffs\r\n",
    "    P_T = np.exp(-r*(T-tau)) * np.maximum(K-S_T,0)\r\n",
    "    return S_tau, P_T\r\n",
    "\r\n",
    "#the function DT(Z,\\theta)\r\n",
    "def data_trans_IS(Z,IS):\r\n",
    "    return Z + IS\r\n",
    "\r\n",
    "#The density function of Z\r\n",
    "def f(y):\r\n",
    "    return stats.norm.pdf(y, loc=0, scale=1)\r\n",
    "\r\n",
    "#The density function of Z_\\theta (note that x is interpreted as theta, needed for the least-squares solver to work properly), variance not included in the parametrisation\r\n",
    "def f_theta(y, x):\r\n",
    "    return stats.norm.pdf(y, loc=x, scale=1)\r\n",
    "\r\n",
    "#Put- und Call-Black-Scholes Formeln\r\n",
    "def d1(K, t, x, sigma, r):\r\n",
    "    return (np.log(x/K)+(r+0.5*sigma**2)*t)/(sigma*np.sqrt(t))\r\n",
    "\r\n",
    "def d2(K, t, x, sigma, r):\r\n",
    "    return (np.log(x/K)+(r-0.5*sigma**2)*t)/(sigma*np.sqrt(t))\r\n",
    "\r\n",
    "def put_true(K, t, x, sigma, r): \r\n",
    "    return K*np.exp(-r*t)*stats.norm.cdf(-d2(K,t,x,sigma,r)) - x*stats.norm.cdf(-d1(K,t,x,sigma,r))\r\n",
    "\r\n",
    "def call_true(K, t, x, sigma, r):\r\n",
    "    return x*stats.norm.cdf(d1(K,t,x,sigma,r)) - K*np.exp(-r*t)*stats.norm.cdf(d2(K,t,x,sigma,r))\r\n",
    "\r\n",
    "#true function l\r\n",
    "def P_T_true(x):\r\n",
    "    return put_true(K=K, t=T-tau, x=x, sigma=sigma, r=r)\r\n",
    "\r\n",
    "#This function describes the approximation of the expression inside the sum of m_2(theta)\r\n",
    "def g_q_alpha_hat_reweighted(x,L,q_alpha_hat):\r\n",
    "    return np.sqrt(f(y=L[:,0])/f_theta(y=L[:,0],x=x))*(L[:,-1]>q_alpha_hat)\r\n",
    "\r\n",
    "#function for estimating GlueVaR in an IS setting\r\n",
    "def GlueVaR_IS(omega, L, alpha, beta, w):\r\n",
    "    j_beta = 0\r\n",
    "    w_sum_tmp = 0\r\n",
    "    while(w_sum_tmp <= (1-beta)):\r\n",
    "        w_sum_tmp += w[j_beta]\r\n",
    "        j_beta += 1\r\n",
    "        \r\n",
    "    j_alpha = j_beta\r\n",
    "    while(w_sum_tmp <= (1-alpha)):\r\n",
    "        w_sum_tmp += w[j_alpha]\r\n",
    "        j_alpha += 1\r\n",
    "        \r\n",
    "    ES_beta = 1/(1-beta) * np.sum(w[0:j_beta-1]*L[0:j_beta-1]) + ( 1 - (1 / (1-beta)) * np.sum(w[0:j_beta-1]) )*L[j_beta]\r\n",
    "    ES_alpha = 1/(1-alpha) * np.sum(w[0:j_alpha-1]*L[0:j_alpha-1]) + ( 1 - (1 / (1-alpha)) * np.sum(w[0:j_alpha-1]) )*L[j_alpha]\r\n",
    "    VaR_alpha = L[j_alpha]\r\n",
    "\r\n",
    "    return omega[0]*ES_beta + omega[1]*ES_alpha + (1-omega[0]-omega[1])*VaR_alpha\r\n",
    "\r\n",
    "#function for estimating GlueVaR\r\n",
    "def GlueVaR(omega, L, alpha, beta):\r\n",
    "    j_beta = int(len(L)*(1-beta))-1\r\n",
    "    j_alpha = int(len(L)*(1-alpha))-1\r\n",
    "\r\n",
    "    ES_beta = 1/(1-beta) * np.sum(L[0:j_beta-1])/len(L) + ( 1 - (j_beta-1)/((1-beta)*len(L)) )*L[j_beta]\r\n",
    "    ES_alpha = 1/(1-alpha) * np.sum(L[0:j_alpha-1])/len(L) + ( 1 - (j_alpha-1)/((1-alpha)*len(L)) )*L[j_alpha]\r\n",
    "    VaR_alpha = L[j_alpha]\r\n",
    "\r\n",
    "    return omega[0]*ES_beta + omega[1]*ES_alpha + (1-omega[0]-omega[1])*VaR_alpha"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Generating realisations of standard normal random variables\r\n",
    "Z_IS = np.random.normal(loc=0, scale=1, size=M_IS)\r\n",
    "V_IS = np.random.normal(loc=0, scale=1, size=M_IS)\r\n",
    "\r\n",
    "#Calculate the risk factor S_tau and the corresponding simulated payoffs P_T\r\n",
    "S_tau_IS, P_T_IS = data_gen(Z=Z_IS, V=V_IS)\r\n",
    "\r\n",
    "#Calculate realisations of L_hat from the training data set using the true function l\r\n",
    "L_hat_IS = np.column_stack((Z_IS, P_T_true(S_tau_IS)))\r\n",
    "L_hat_IS_sort = L_hat_IS[L_hat_IS[:,-1].argsort()[::-1]]\r\n",
    "\r\n",
    "#Calculating the corresponding estimator for Value-at-Risk in order to approximate g\r\n",
    "q_alpha_hat_IS = L_hat_IS_sort[int(M_IS*(1-alpha_IS)-1), -1]\r\n",
    "print('q_alpha_hat_IS:',q_alpha_hat_IS)\r\n",
    "\r\n",
    "#Calculating the (hopefully) approximately optimal \\theta^* by minimising m_2 using the approximated g\r\n",
    "IS = optimize.least_squares(g_q_alpha_hat_reweighted, x0=0, args=(L_hat_IS, q_alpha_hat_IS)).x\r\n",
    "\r\n",
    "print(IS)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "q_alpha_hat_IS: 7.241181376609681\n",
      "[-2.17912095]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "run = 1\r\n",
    "for j in range(100):\r\n",
    "    #Generating simulations for standard normal random variables for  Monte Carlo estimation of risk measures\r\n",
    "    Z_MC = np.random.normal(loc=0, scale=1, size=M_MC)\r\n",
    "    V_MC = np.random.normal(loc=0, scale=1, size=M_MC)\r\n",
    "    #calculating DT(Z,\\theta^*)\r\n",
    "    Z_MC_IS = data_trans_IS(Z_MC,IS)\r\n",
    "\r\n",
    "    #Calculate the risk factor S_tau and the corresponding simulated payoffs P_T with original and IS distribution\r\n",
    "    S_tau_MC,P_T_MC = data_gen(Z=Z_MC,V=V_MC)\r\n",
    "    S_tau_MC_IS,P_T_MC_IS = data_gen(Z=Z_MC_IS,V=V_MC)\r\n",
    "    \r\n",
    "    #computation of option price depending on the risk factor S_tau according to the models, i.e. computation of L_hat_i's with original distribution\r\n",
    "    L_hat = P_T_true(x=S_tau_MC)\r\n",
    "    L_hat_sort = np.sort(L_hat)[::-1]\r\n",
    "    \r\n",
    "    #calculation of GlueVaR estimator without IS\r\n",
    "    GlueVaR_hat = GlueVaR(omega=omega_Glue,L=L_hat_sort,alpha=alpha_Glue,beta=beta_Glue)\r\n",
    "    \r\n",
    "    #computation of option price depending on the risk factor S_tau according to the models, i.e. computation of L_hat_i's with IS distribution\r\n",
    "    L_hat_IS = P_T_true(x=S_tau_MC_IS)\r\n",
    "    L_hat_c_IS = np.column_stack((Z_MC_IS, L_hat_IS))\r\n",
    "    \r\n",
    "    #calculation of GlueVaR estimator with IS\r\n",
    "    L_hat_c_sort_IS = L_hat_c_IS[L_hat_c_IS[:,-1].argsort()[::-1]]\r\n",
    "    w = f(L_hat_c_sort_IS[:,0])/(M_MC*f_theta(x=IS, y=L_hat_c_sort_IS[:,0]))\r\n",
    "\r\n",
    "    GlueVaR_hat_IS = GlueVaR_IS(omega=omega_Glue,L=L_hat_c_sort_IS[:,-1],alpha=alpha_Glue,beta=beta_Glue,w=w)\r\n",
    "    \r\n",
    "    #save results for further evaluation\r\n",
    "    output = np.array([GlueVaR_hat,GlueVaR_hat_IS])\r\n",
    "    \r\n",
    "    joblib.dump(output, filepath+'output'+str(j)+'_'+str(run)+'.joblib')\r\n",
    "    #prints just for checking while the notebook is running\r\n",
    "    print(j)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}