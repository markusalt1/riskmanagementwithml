{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.utils import shuffle\r\n",
    "from scipy import stats\r\n",
    "from scipy import optimize\r\n",
    "import joblib\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "\r\n",
    "#directory for saving results\r\n",
    "filepath = \".../Resultate_final/Put/IS/test/Put_VaR_ES_IS_1_test_saved/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Market and option parameters as in section 4.1 of 'Assessing Asset-Liability Risk with Neural Networks' (Cheridito, Ery, WÃ¼thrich 2020)\r\n",
    "s_0 = 100\r\n",
    "r = 0.01\r\n",
    "mu = 0.05\r\n",
    "sigma = 0.2\r\n",
    "tau = 1/52\r\n",
    "T = 1/3\r\n",
    "K = 100\r\n",
    "\r\n",
    "#quantile for which the IS distribution is computed\r\n",
    "alpha_IS = 0.995\r\n",
    "#Confidence levels for Value-at-Risk and Expected Shortfall\r\n",
    "alpha_VaR = 0.995\r\n",
    "alpha_ES = 0.99"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Sizes for training set, validation set, test set, and set size for Monte Carlo estimation of the risk measures\r\n",
    "M_1 = 1500000\r\n",
    "M_2 = 500000\r\n",
    "M_3 = 500000\r\n",
    "#ignore N or N_2 in the following. Was kept just in case, but not used.\r\n",
    "N_2 = 1\r\n",
    "M_MC = 500000\r\n",
    "#size of the set of data points used to calculate an IS density\r\n",
    "M_IS = 2000000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Calculating simulated values of S_tau and simulated payoffs from standard normal random variable simulations\r\n",
    "def data_gen(Z,V):\r\n",
    "    #simulate S_tau under P\r\n",
    "    S_tau = s_0 * np.exp( (mu-0.5*sigma**2)*tau + sigma*np.sqrt(tau)*Z)\r\n",
    "    #Simulate S_T given S_tau under Q\r\n",
    "    S_T = S_tau * np.exp( (r-0.5*sigma**2)*(T-tau) + sigma*np.sqrt(T-tau)*V)\r\n",
    "    #Calculate corresponding simulated discounted payoffs\r\n",
    "    P_T = np.exp(-r*(T-tau)) * np.maximum(K-S_T,0)\r\n",
    "    return S_tau, P_T\r\n",
    "\r\n",
    "#the function DT(Z,\\theta)\r\n",
    "def data_trans_IS(Z,IS):\r\n",
    "    return Z*IS[1] + IS[0]\r\n",
    "\r\n",
    "#The density function of Z\r\n",
    "def f(y):\r\n",
    "    return stats.norm.pdf(y, loc=0, scale=1)\r\n",
    "\r\n",
    "#The density function of Z_\\theta (note that \\theta is replaced by x; this is needed for the least-squares solver to work), variance included in the parametrisation\r\n",
    "def f_theta(x, y):\r\n",
    "    return stats.norm.pdf(y, loc=x[0], scale=x[1])\r\n",
    "\r\n",
    "#Put- und Call-Black-Scholes Formeln\r\n",
    "def d1(K, t, x, sigma, r):\r\n",
    "    return (np.log(x/K)+(r+0.5*sigma**2)*t)/(sigma*np.sqrt(t))\r\n",
    "\r\n",
    "def d2(K, t, x, sigma, r):\r\n",
    "    return (np.log(x/K)+(r-0.5*sigma**2)*t)/(sigma*np.sqrt(t))\r\n",
    "\r\n",
    "def put_true(K, t, x, sigma, r): \r\n",
    "    return K*np.exp(-r*t)*stats.norm.cdf(-d2(K,t,x,sigma,r)) - x*stats.norm.cdf(-d1(K,t,x,sigma,r))\r\n",
    "\r\n",
    "def call_true(K, t, x, sigma, r):\r\n",
    "    return x*stats.norm.cdf(d1(K,t,x,sigma,r)) - K*np.exp(-r*t)*stats.norm.cdf(d2(K,t,x,sigma,r))\r\n",
    "\r\n",
    "#true function l\r\n",
    "def P_T_true(x):\r\n",
    "    return put_true(K=K, t=T-tau, x=x, sigma=sigma, r=r)\r\n",
    "\r\n",
    "#This function describes the approximation of the expression inside the sum of m_2(theta)\r\n",
    "def g_q_alpha_hat_reweighted(x,L,q_alpha_hat):\r\n",
    "    return np.sqrt(f(y=L[:,0])/f_theta(y=L[:,0],x=x))*(L[:,-1]>q_alpha_hat)\r\n",
    "\r\n",
    "#bounds for the IS density parameters (for the mean parameter bounds are necessary, the standard deviation parameter however needs to be non-negative)\r\n",
    "bnds_lower = [-np.inf, 0]\r\n",
    "bnds_upper = [np.inf, np.inf]\r\n",
    "bnds = (bnds_lower, bnds_upper)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Generating realisations of standard normal random variables\r\n",
    "Z_IS = np.random.normal(loc=0, scale=1, size=M_IS)\r\n",
    "V_IS = np.random.normal(loc=0, scale=1, size=M_IS)\r\n",
    "\r\n",
    "#Calculate the risk factor S_tau and the corresponding simulated payoffs P_T\r\n",
    "S_tau_IS, P_T_IS = data_gen(Z=Z_IS, V=V_IS)\r\n",
    "\r\n",
    "#Calculate realisations of L_hat from the training data set using the true function l\r\n",
    "L_hat_IS = np.column_stack((Z_IS, P_T_true(S_tau_IS)))\r\n",
    "L_hat_IS_sort = L_hat_IS[L_hat_IS[:,-1].argsort()[::-1]]\r\n",
    "\r\n",
    "#Calculating the corresponding estimator for Value-at-Risk in order to approximate g\r\n",
    "q_alpha_hat_IS = L_hat_IS_sort[int(M_IS*(1-alpha_IS)-1), -1]\r\n",
    "print('q_alpha_hat_IS:',q_alpha_hat_IS)\r\n",
    "\r\n",
    "#Calculating the (hopefully) approximately optimal \\theta^* by minimising m_2 using the approximated g\r\n",
    "IS_obj = optimize.least_squares(g_q_alpha_hat_reweighted, x0=np.array([0,1]), args=(L_hat_IS, q_alpha_hat_IS), bounds=bnds)\r\n",
    "IS = IS_obj.x\r\n",
    "print(IS)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "q_alpha_hat_IS: 8.342059689048256\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "/scratch/slurm_tmpdir/job_20138784/ipykernel_3974210/2114570057.py:38: RuntimeWarning: divide by zero encountered in true_divide\n",
      "  return np.sqrt(f(y=L[:,0])/f_theta(y=L[:,0],x=x))*(L[:,-1]>q_alpha_hat)\n",
      "/scratch/slurm_tmpdir/job_20138784/ipykernel_3974210/2114570057.py:38: RuntimeWarning: overflow encountered in true_divide\n",
      "  return np.sqrt(f(y=L[:,0])/f_theta(y=L[:,0],x=x))*(L[:,-1]>q_alpha_hat)\n",
      "/scratch/slurm_tmpdir/job_20138784/ipykernel_3974210/2114570057.py:38: RuntimeWarning: invalid value encountered in multiply\n",
      "  return np.sqrt(f(y=L[:,0])/f_theta(y=L[:,0],x=x))*(L[:,-1]>q_alpha_hat)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[-2.83649144  0.43991149]\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "IS_obj.message"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'`ftol` termination condition is satisfied.'"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "Even though error messages appear the algorithm succesfully converged thus we take the result to be meaningful and proceed."
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "source": [
    "run = 1\r\n",
    "for j in range(100):\r\n",
    "    #Generating simulations for standard normal random variables for  Monte Carlo estimation of risk measures\r\n",
    "    Z_MC = np.random.normal(loc=0, scale=1, size=M_MC)\r\n",
    "    V_MC = np.random.normal(loc=0, scale=1, size=M_MC)\r\n",
    "    #calculating DT(Z,\\theta^*)\r\n",
    "    Z_MC_IS = data_trans_IS(Z_MC,IS)\r\n",
    "\r\n",
    "    #Calculate the risk factor S_tau and the corresponding simulated payoffs P_T with original and IS distribution\r\n",
    "    S_tau_MC,P_T_MC = data_gen(Z=Z_MC,V=V_MC)\r\n",
    "    S_tau_MC_IS,P_T_MC_IS = data_gen(Z=Z_MC_IS,V=V_MC)\r\n",
    "    \r\n",
    "    #computation of option price depending on the risk factor S_tau according to the models, i.e. computation of L_hat_i's with original distribution\r\n",
    "    L_hat = P_T_true(x=S_tau_MC)\r\n",
    "    L_hat_sort = np.sort(L_hat)[::-1]\r\n",
    "    \r\n",
    "    #calculation of Value-at-Risk and Expected Shortfall estimators without IS\r\n",
    "    j_VaR = int(M_MC*(1-alpha_VaR)-1)\r\n",
    "    VaR_hat = L_hat_sort[j_VaR]\r\n",
    "    \r\n",
    "    j_ES = int(M_MC*(1-alpha_ES)-1)\r\n",
    "    ES_hat = (1/(1-alpha_ES)) * np.sum(L_hat_sort[0:j_ES-1])/M_MC + ( 1 - (j_ES-1)/((1-alpha_ES)*M_MC) )*L_hat_sort[j_ES]\r\n",
    "    \r\n",
    "    #computation of option price depending on the risk factor S_tau according to the models, i.e. computation of L_hat_i's with IS distribution\r\n",
    "    L_hat_IS = P_T_true(x=S_tau_MC_IS)\r\n",
    "    L_hat_c_IS = np.column_stack((Z_MC_IS, L_hat_IS))\r\n",
    "    \r\n",
    "    #calculation of Value-at-Risk and Expected Shortfall estimators with IS\r\n",
    "    L_hat_c_sort_IS = L_hat_c_IS[L_hat_c_IS[:,-1].argsort()[::-1]]\r\n",
    "    w = f(L_hat_c_sort_IS[:,0])/(M_MC*f_theta(x=IS, y=L_hat_c_sort_IS[:,0]))\r\n",
    "\r\n",
    "    j_VaR = 0\r\n",
    "    w_sum_tmp = 0\r\n",
    "    while (w_sum_tmp <= (1-alpha_VaR) and j_VaR<M_MC):\r\n",
    "        w_sum_tmp += w[j_VaR]\r\n",
    "        j_VaR += 1\r\n",
    "    VaR_hat_IS = L_hat_c_sort_IS[j_VaR,-1]\r\n",
    "\r\n",
    "    j_ES = 0\r\n",
    "    w_sum_tmp = 0\r\n",
    "    while (w_sum_tmp <= (1-alpha_ES) and j_ES<M_MC):\r\n",
    "        w_sum_tmp += w[j_ES]\r\n",
    "        j_ES += 1\r\n",
    "    ES_hat_IS = (1/(1-alpha_ES)) * np.sum(w[0:j_ES-1]*L_hat_c_sort_IS[0:j_ES-1,-1]) + ( 1 - (1 / (1-alpha_ES)) * np.sum(w[0:j_ES-1]) )*L_hat_c_sort_IS[j_ES,-1]\r\n",
    "    \r\n",
    "    #save results for further evaluation\r\n",
    "    output = np.array([VaR_hat,VaR_hat_IS,ES_hat,ES_hat_IS])\r\n",
    "    \r\n",
    "    joblib.dump(output, filepath+'output'+str(j)+'_'+str(run)+'.joblib')\r\n",
    "    #prints just for checking while the notebook is running\r\n",
    "    print(j)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}