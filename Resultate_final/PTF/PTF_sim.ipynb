{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Results were produced in stints. This is the number of the last stint.\r\n",
    "run = 3"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "import matplotlib.pyplot as plt\r\n",
    "from scipy import stats\r\n",
    "import joblib\r\n",
    "\r\n",
    "#folder for saving results\r\n",
    "filepath = \".../Resultate_final/PTF/saved_sim/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Market and option parameters as in section 4.2 of 'Assessing Asset-Liability Risk with Neural Networks' (Cheridito, Ery, Wüthrich 2020)\r\n",
    "s_0 = 100\r\n",
    "r = 0.01\r\n",
    "corr= 0.3\r\n",
    "tau = 1/52\r\n",
    "T = 1/3\r\n",
    "K = 100\r\n",
    "\r\n",
    "mu = np.empty(20)\r\n",
    "sigma = np.empty(20)\r\n",
    "for i in range(0,10):\r\n",
    "    mu[i] = mu[i+10] = (3+(i+1)/2)/100\r\n",
    "    sigma[i] = sigma[i+10] = (15+(i+1))/100\r\n",
    "\r\n",
    "cov_mat = np.empty((20,20))\r\n",
    "for i in range(0,20):\r\n",
    "    for j in range(0,20):\r\n",
    "        if i != j:\r\n",
    "            cov_mat[i,j] = corr\r\n",
    "        else:\r\n",
    "            cov_mat[i,j] = 1\r\n",
    "\r\n",
    "C = np.linalg.cholesky(cov_mat)\r\n",
    "\r\n",
    "#Confidence levels and parameters for Value-at-Risk, Expected Shortfall and GlueVaR\r\n",
    "alpha_VaR = 0.995\r\n",
    "alpha_ES = 0.99\r\n",
    "alpha_Glue = 0.95\r\n",
    "beta_Glue = 0.995\r\n",
    "omega_Glue = np.array([1/3,1/3])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Sizes for training set, validation set, test set, and set size for Monte Carlo estimation of the risk measures\r\n",
    "M_1 = 1500000\r\n",
    "M_2 = 500000\r\n",
    "M_3 = 500000\r\n",
    "#ignore N or N_2 in the following. Was kept just in case, but not used.\r\n",
    "N_2 = 1\r\n",
    "M_MC = 500000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Function for calculating simulated values of S_tau and simulated payoffs P_T from simulations of multivariate standard normal random variables\r\n",
    "def data_gen(M,N,Z,V):\r\n",
    "    #correlating the independent components\r\n",
    "    Z = np.transpose(np.matmul(C,np.transpose(Z)))\r\n",
    "    V = np.transpose(np.matmul(C,np.transpose(V)))\r\n",
    "\r\n",
    "    #simulate S_tau under P\r\n",
    "    S_tau_pre = np.empty((M, 20))\r\n",
    "    for j in range(0,20):\r\n",
    "        S_tau_pre[:,j] = s_0 * np.exp( (mu[j]-0.5*sigma[j]**2)*tau + np.sqrt(tau)*sigma[j]*Z[:,j] )\r\n",
    "    S_tau = np.tile(S_tau_pre, (N,1))\r\n",
    "\r\n",
    "    #simulate S_T  given S_tau under Q\r\n",
    "    S_T = np.empty((N*M,20))\r\n",
    "    for j in range(0,20):\r\n",
    "        S_T[:,j] = S_tau[:,j] * np.exp( (r-0.5*sigma[j]**2)*(T-tau) + np.sqrt(T-tau)*sigma[j]*V[:,j] )\r\n",
    "\r\n",
    "    #compute discounted option payoffs\r\n",
    "    P_T_pre =np.empty((len(S_T), 20))\r\n",
    "    for j in range(0,10):\r\n",
    "        P_T_pre[:,j] = np.exp(-r*(T-tau)) * np.maximum(S_T[:,j]-K,0)\r\n",
    "    for j in range(10,20):\r\n",
    "        P_T_pre[:,j] = np.exp(-r*(T-tau)) * np.maximum(K-S_T[:,j],0)\r\n",
    "    P_T = np.sum(P_T_pre, axis=1)\r\n",
    "    return S_tau,P_T\r\n",
    "\r\n",
    "#Function for the computation of GlueVaR\r\n",
    "def GlueVaR(omega, L, alpha, beta):\r\n",
    "    j_beta = int(len(L)*(1-beta))-1\r\n",
    "    j_alpha = int(len(L)*(1-alpha))-1\r\n",
    "\r\n",
    "    ES_beta = 1/(1-beta) * np.sum(L[0:j_beta-1])/len(L) + ( 1 - (j_beta-1)/((1-beta)*len(L)) )*L[j_beta]\r\n",
    "    ES_alpha = 1/(1-alpha) * np.sum(L[0:j_alpha-1])/len(L) + ( 1 - (j_alpha-1)/((1-alpha)*len(L)) )*L[j_alpha]\r\n",
    "    VaR_alpha = L[j_alpha]\r\n",
    "\r\n",
    "    return omega[0]*ES_beta + omega[1]*ES_alpha + (1-omega[0]-omega[1])*VaR_alpha"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for j in range(100):\r\n",
    "    #simulation of multivariate standard normal random variables\r\n",
    "    Z_train = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=int(M_1/N_2))\r\n",
    "    V_train = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_1)\r\n",
    "    Z_val = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_2)\r\n",
    "    V_val = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_2)\r\n",
    "    Z_test = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_3)\r\n",
    "    V_test = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_3)\r\n",
    "    Z_MC = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_MC)\r\n",
    "    V_MC = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_MC)\r\n",
    "\r\n",
    "    #Calculate the risk factor S_tau and the corresponding simulated payoffs P_T\r\n",
    "    S_tau_train, P_T_train = data_gen(M=int(M_1/N_2), N=N_2, Z=Z_train, V=V_train)\r\n",
    "    S_tau_val, P_T_val = data_gen(M=M_2, N=1, Z=Z_val, V=V_val)\r\n",
    "    S_tau_test, P_T_test = data_gen(M=M_3, N=1, Z=Z_test, V=V_test)\r\n",
    "    S_tau_MC, P_T_MC = data_gen(M=M_MC, N=1, Z=Z_MC, V=V_MC)\r\n",
    "\r\n",
    "\r\n",
    "    #define and compile neural network model, setup as in section 4.2 of 'Assessing Asset-Liability Risk with Neural Networks' (Cheridito, Ery, Wüthrich 2020)\r\n",
    "    bi = np.log( np.sum(P_T_train)/len(P_T_train) )\r\n",
    "    model = tf.keras.models.Sequential([\r\n",
    "        tf.keras.layers.BatchNormalization(input_shape=(20,)),\r\n",
    "        tf.keras.layers.Dense(20, activation='tanh'),\r\n",
    "        tf.keras.layers.Dense(20, activation='tanh'),\r\n",
    "        tf.keras.layers.Dense(1, activation='exponential', bias_initializer=tf.keras.initializers.Constant(value=bi))])\r\n",
    "    #compilation\r\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\r\n",
    "    #training\r\n",
    "    hist = model.fit(x=S_tau_train, y=P_T_train, epochs=100, batch_size=10000, validation_data=(S_tau_val,P_T_val), verbose=0)\r\n",
    "\r\n",
    "    #definition of random forest regressor\r\n",
    "    rfr = RandomForestRegressor(n_estimators=400, criterion='squared_error', max_features=6, min_samples_leaf=50, bootstrap=True, verbose=0, warm_start=True, n_jobs=-1)\r\n",
    "    #training\r\n",
    "    rfr.fit(X=S_tau_train, y=P_T_train)\r\n",
    "\r\n",
    "    #Calculating the parts of the test set that fall into B_1 and B_2\r\n",
    "    s_20_1 = s_0 * np.exp((mu[0:3]-0.5*sigma[0:3]**2)*tau + sigma[0:3]*np.sqrt(tau)*stats.norm.ppf(0.2, loc=0, scale=1))\r\n",
    "    s_80_1 = s_0 * np.exp((mu[9:12]-0.5*sigma[9:12]**2)*tau + sigma[9:12]*np.sqrt(tau)*stats.norm.ppf(0.8, loc=0, scale=1))\r\n",
    "    s_20_2 = s_0 * np.exp((mu[9:12]-0.5*sigma[9:12]**2)*tau + sigma[9:12]*np.sqrt(tau)*stats.norm.ppf(0.2, loc=0, scale=1))\r\n",
    "    s_80_2 = s_0 * np.exp((mu[0:3]-0.5*sigma[0:3]**2)*tau + sigma[0:3]*np.sqrt(tau)*stats.norm.ppf(0.8, loc=0, scale=1))\r\n",
    "    B_1 = np.apply_along_axis(np.all, axis=1, arr=np.column_stack( (np.apply_along_axis(np.all, axis=1, arr=S_tau_test[:,0:3] > s_20_1), np.apply_along_axis(np.all, axis=1, arr=S_tau_test[:,9:12] < s_80_1)) ) )\r\n",
    "    B_2 = np.apply_along_axis(np.all, axis=1, arr=np.column_stack( (np.apply_along_axis(np.all, axis=1, arr=S_tau_test[:,0:3] < s_80_2), np.apply_along_axis(np.all, axis=1, arr=S_tau_test[:,9:12] > s_20_2)) ) )\r\n",
    "\r\n",
    "    #computation of the metrics (a), (b), (c) with B_1 and (c) with B_2 for the neural network\r\n",
    "    P_T_pred_NN = model.predict(S_tau_test)[:,0]\r\n",
    "    mse_train_NN = hist.history['mse'][-1]\r\n",
    "    mse_val_NN = hist.history['val_mse'][-1]\r\n",
    "    print('Val MSE NN:',mse_val_NN)\r\n",
    "    mc_tmp = P_T_pred_NN - P_T_test\r\n",
    "    metric_a_NN = np.sum(mc_tmp)/len(P_T_test)\r\n",
    "    metric_b_NN = np.sum((mc_tmp)*P_T_pred_NN)/len(P_T_test)\r\n",
    "    metric_c_B_1_NN = np.sum(mc_tmp[B_1])/len(P_T_test)\r\n",
    "    metric_c_B_2_NN = np.sum(mc_tmp[B_2])/len(P_T_test)\r\n",
    "\r\n",
    "    #computation of the metrics (a), (b), (c) with B_1 and (c) with B_2 and training/validation MSE for the random forest\r\n",
    "    mse_train_RF = mean_squared_error(y_pred=rfr.predict(S_tau_train),y_true=P_T_train)\r\n",
    "    P_T_pred_RF = rfr.predict(S_tau_test)\r\n",
    "    mse_val_RF = mean_squared_error(y_pred=P_T_pred_RF,y_true=P_T_test)\r\n",
    "    print('Val MSE_RF:',mse_val_RF)\r\n",
    "    mc_tmp = P_T_pred_RF - P_T_test\r\n",
    "    metric_a_RF = np.sum(mc_tmp)/len(P_T_test)\r\n",
    "    metric_b_RF = np.sum((mc_tmp)*P_T_pred_RF)/len(P_T_test)\r\n",
    "    metric_c_B_1_RF = np.sum(mc_tmp[B_1])/len(P_T_test)\r\n",
    "    metric_c_B_2_RF = np.sum(mc_tmp[B_2])/len(P_T_test)\r\n",
    "\r\n",
    "\r\n",
    "    #computation of risk measure estimators\r\n",
    "    #Prediction of total of all option prices\r\n",
    "    P_T_pred_MC_NN = model.predict(S_tau_MC)[:,0]\r\n",
    "    P_T_pred_MC_RF = rfr.predict(S_tau_MC)\r\n",
    "\r\n",
    "    L_NN = np.sort(P_T_pred_MC_NN)[::-1]\r\n",
    "    L_RF = np.sort(P_T_pred_MC_RF)[::-1]\r\n",
    "\r\n",
    "    #Value-at-Risk\r\n",
    "    j_VaR = int(M_MC*(1-alpha_VaR))-1\r\n",
    "    VaR_hat_NN = L_NN[j_VaR]\r\n",
    "    VaR_hat_RF = L_RF[j_VaR]\r\n",
    "    \r\n",
    "    #Expected Shortfall\r\n",
    "    j_ES = int(M_MC*(1-alpha_ES))-1\r\n",
    "    ES_hat_NN = 1/(1-alpha_ES) * np.sum(L_NN[0:j_ES-1])/M_MC + ( 1 - (j_ES-1)/((1-alpha_ES)*M_MC) )*L_NN[j_ES]\r\n",
    "    ES_hat_RF = 1/(1-alpha_ES) * np.sum(L_RF[0:j_ES-1])/M_MC + ( 1 - (j_ES-1)/((1-alpha_ES)*M_MC) )*L_RF[j_ES]\r\n",
    "    \r\n",
    "    #GlueVaR\r\n",
    "    GlueVaR_hat_NN = GlueVaR(omega=omega_Glue, L=L_NN, alpha=alpha_Glue, beta=beta_Glue)\r\n",
    "    GlueVaR_hat_RF = GlueVaR(omega=omega_Glue, L=L_RF, alpha=alpha_Glue, beta=beta_Glue)\r\n",
    "    print('Estimates NN:',VaR_hat_NN,ES_hat_NN,GlueVaR_hat_NN)\r\n",
    "    print('Estimates RF:',VaR_hat_RF,ES_hat_RF,GlueVaR_hat_RF)\r\n",
    "\r\n",
    "    #save results for further evaluation\r\n",
    "    output = np.array([[mse_train_NN,mse_val_NN,metric_a_NN,metric_b_NN,metric_c_B_1_NN,metric_c_B_2_NN,VaR_hat_NN,ES_hat_NN,GlueVaR_hat_NN],\r\n",
    "                      [mse_train_RF,mse_val_RF,metric_a_RF,metric_b_RF,metric_c_B_1_RF,metric_c_B_2_RF,VaR_hat_RF,ES_hat_RF,GlueVaR_hat_RF]])\r\n",
    "\r\n",
    "    joblib.dump(output,filepath+'output_'+str(run)+'_'+str(j)+'.joblib')\r\n",
    "    #prints just for checking while the notebook is running\r\n",
    "    print(j)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-11-02 20:22:27.756455: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /opt/bwhpc/common/devel/cuda/11.4/lib64:/opt/bwhpc/common/compiler/gnu/10.2.0/lib:/opt/bwhpc/common/compiler/gnu/10.2.0/lib64:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-10.2/lib:/opt/bwhpc/common/mpi/openmpi/4.1.1-gnu-10.2/lib64\n",
      "2021-11-02 20:22:27.784077: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2021-11-02 20:22:27.784204: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (uc2n466.localdomain): /proc/driver/nvidia/version does not exist\n",
      "2021-11-02 20:22:27.822815: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-02 20:22:30.370789: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Val MSE NN: 1157.6416015625\n",
      "Val MSE_RF: 1163.8560339183705\n",
      "Estimates NN: 109.00272 109.54302693176271 106.74819060099284\n",
      "Estimates RF: 106.49996220376262 107.07083997866667 104.68165893966346\n",
      "0\n",
      "Val MSE NN: 1158.2738037109375\n",
      "Val MSE_RF: 1162.3437348620853\n",
      "Estimates NN: 110.53606 111.20630493774416 108.10699053487141\n",
      "Estimates RF: 106.83561113430187 107.43731407597014 104.93267772368682\n",
      "1\n",
      "Val MSE NN: 1158.969482421875\n",
      "Val MSE_RF: 1159.9496009184613\n",
      "Estimates NN: 109.36378 109.86603711242677 106.99941491292319\n",
      "Estimates RF: 106.96697098290224 107.609273616062 105.03237104905057\n",
      "2\n",
      "Val MSE NN: 1158.126708984375\n",
      "Val MSE_RF: 1158.5275813405767\n",
      "Estimates NN: 110.43596 111.03008006896974 107.95805806091309\n",
      "Estimates RF: 106.75125545043244 107.26398291129676 104.80639099728197\n",
      "3\n",
      "Val MSE NN: 1160.1044921875\n",
      "Val MSE_RF: 1158.6566252854618\n",
      "Estimates NN: 110.767265 111.41791625366211 108.10700551635742\n",
      "Estimates RF: 106.81646370948465 107.44119615623408 104.89860693839353\n",
      "4\n",
      "Val MSE NN: 1154.829833984375\n",
      "Val MSE_RF: 1159.9062554309512\n",
      "Estimates NN: 109.82632 110.45313271789553 107.38486850402833\n",
      "Estimates RF: 106.89537410413405 107.41040540809671 104.87878172559965\n",
      "5\n",
      "Val MSE NN: 1152.4593505859375\n",
      "Val MSE_RF: 1160.8035054584823\n",
      "Estimates NN: 110.75269 111.2982045593262 108.19447444173178\n",
      "Estimates RF: 106.85250953441559 107.48781415665628 104.95920376558024\n",
      "6\n",
      "Val MSE NN: 1162.0928955078125\n",
      "Val MSE_RF: 1161.5574518259155\n",
      "Estimates NN: 111.794876 112.43067838134768 109.14272974853515\n",
      "Estimates RF: 106.81644403701472 107.4418563990597 104.91920131620981\n",
      "7\n",
      "Val MSE NN: 1160.2041015625\n",
      "Val MSE_RF: 1165.9902680443197\n",
      "Estimates NN: 110.36647 111.03586105957032 107.87870834777831\n",
      "Estimates RF: 107.13632575938944 107.79053776977813 105.15346618677702\n",
      "8\n",
      "Val MSE NN: 1154.68359375\n",
      "Val MSE_RF: 1157.481633153403\n",
      "Estimates NN: 111.4555 112.13936227111819 108.75896125406902\n",
      "Estimates RF: 107.33264425917123 107.87922978608265 105.23258203130754\n",
      "9\n",
      "Val MSE NN: 1154.5634765625\n",
      "Val MSE_RF: 1158.9377969717061\n",
      "Estimates NN: 109.08357 109.67430875549319 106.69865884195963\n",
      "Estimates RF: 106.86792948903506 107.48975372217178 104.95359182580026\n",
      "10\n",
      "Val MSE NN: 1158.749267578125\n",
      "Val MSE_RF: 1159.1813851125817\n",
      "Estimates NN: 110.05851 110.67500811462405 107.54284155822756\n",
      "Estimates RF: 106.89851066528243 107.53428706714207 104.95034468725939\n",
      "11\n",
      "Val MSE NN: 1157.1810302734375\n",
      "Val MSE_RF: 1161.3358718028778\n",
      "Estimates NN: 109.5558 110.11487885437013 107.29626294311524\n",
      "Estimates RF: 106.81762836963526 107.43584379999426 104.94521226459975\n",
      "12\n",
      "Val MSE NN: 1156.8094482421875\n",
      "Val MSE_RF: 1153.9181547188603\n",
      "Estimates NN: 109.79265 110.46815151367188 107.36521644571943\n",
      "Estimates RF: 107.05804139701416 107.6970586811924 105.0722692607051\n",
      "13\n",
      "Val MSE NN: 1159.830322265625\n",
      "Val MSE_RF: 1162.9988808473365\n",
      "Estimates NN: 110.011284 110.68955798339844 107.51415319559734\n",
      "Estimates RF: 107.02906856092315 107.77000532005258 105.13147682655809\n",
      "14\n",
      "Val MSE NN: 1156.8438720703125\n",
      "Val MSE_RF: 1158.0412184105417\n",
      "Estimates NN: 109.520546 110.14071271362306 107.11415215759277\n",
      "Estimates RF: 107.39954323540627 108.03205607814468 105.28089235930597\n",
      "15\n",
      "Val MSE NN: 1154.090576171875\n",
      "Val MSE_RF: 1160.3795515236789\n",
      "Estimates NN: 110.46577 111.15564122009279 107.91351577596029\n",
      "Estimates RF: 107.14376882957649 107.82256362289922 105.13705846345273\n",
      "16\n",
      "Val MSE NN: 1154.9991455078125\n",
      "Val MSE_RF: 1161.1081643330224\n",
      "Estimates NN: 108.75679 109.32718276672365 106.48466486897786\n",
      "Estimates RF: 106.82732320826993 107.41269438531256 104.87480739044943\n",
      "17\n",
      "Val MSE NN: 1157.94140625\n",
      "Val MSE_RF: 1160.2006967485286\n",
      "Estimates NN: 109.56949 110.16743521423341 107.2018614436849\n",
      "Estimates RF: 106.93976107195384 107.6499180654397 105.03049459079045\n",
      "18\n",
      "Val MSE NN: 1151.126220703125\n",
      "Val MSE_RF: 1159.6030960542498\n",
      "Estimates NN: 109.421936 109.99259443969729 107.18394814514161\n",
      "Estimates RF: 106.83616917217267 107.31048635535592 104.86590240073173\n",
      "19\n",
      "Val MSE NN: 1153.259765625\n",
      "Val MSE_RF: 1161.9518155319104\n",
      "Estimates NN: 109.92608 110.52140504150393 107.58766240214031\n",
      "Estimates RF: 106.80346243223613 107.35238413736974 104.87954434188444\n",
      "20\n",
      "Val MSE NN: 1158.3477783203125\n",
      "Val MSE_RF: 1159.2058222749802\n",
      "Estimates NN: 110.16935 110.76207250976564 107.78278744954427\n",
      "Estimates RF: 106.98856119319639 107.48497970468547 104.92881931362535\n",
      "21\n",
      "Val MSE NN: 1156.9119873046875\n",
      "Val MSE_RF: 1163.2614147008385\n",
      "Estimates NN: 110.13269 110.7257518096924 107.75496321370443\n",
      "Estimates RF: 106.82747255451969 107.50311993112523 104.99032216850458\n",
      "22\n",
      "Val MSE NN: 1161.5318603515625\n",
      "Val MSE_RF: 1163.0044264316246\n",
      "Estimates NN: 112.34209 113.08747887268068 109.68811086568198\n",
      "Estimates RF: 106.92841565665374 107.45792148854754 104.92302740466786\n",
      "23\n",
      "Val MSE NN: 1157.88134765625\n",
      "Val MSE_RF: 1166.9733955073525\n",
      "Estimates NN: 109.24119 109.82482889404298 106.78599329101564\n",
      "Estimates RF: 106.93593426697272 107.5392157228738 104.97481551133393\n",
      "24\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/slurm_tmpdir/job_20147728/ipykernel_919122/1405710568.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     27\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'mse'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0;31m#training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0mhist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS_tau_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mP_T_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_tau_val\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mP_T_val\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;31m#definition of random forest regressor\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2021-09-30/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1213\u001b[0m                 \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1214\u001b[0m                 steps_per_execution=self._steps_per_execution)\n\u001b[0;32m-> 1215\u001b[0;31m           val_logs = self.evaluate(\n\u001b[0m\u001b[1;32m   1216\u001b[0m               \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1217\u001b[0m               \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_y\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2021-09-30/lib/python3.8/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1499\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprofiler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstep_num\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_r\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1500\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1501\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1502\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1503\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2021-09-30/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    883\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    884\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mOptionalXlaContext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jit_compile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 885\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    886\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2021-09-30/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    922\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    923\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 924\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    925\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mALLOW_DYNAMIC_VARIABLE_CREATION\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    926\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2021-09-30/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   3037\u001b[0m       (graph_function,\n\u001b[1;32m   3038\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0;32m-> 3039\u001b[0;31m     return graph_function._call_flat(\n\u001b[0m\u001b[1;32m   3040\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[1;32m   3041\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2021-09-30/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1961\u001b[0m         and executing_eagerly):\n\u001b[1;32m   1962\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1963\u001b[0;31m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0m\u001b[1;32m   1964\u001b[0m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[1;32m   1965\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2021-09-30/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    589\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0m_InterpolateFunctionError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    590\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcancellation_manager\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 591\u001b[0;31m           outputs = execute.execute(\n\u001b[0m\u001b[1;32m    592\u001b[0m               \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msignature\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    593\u001b[0m               \u001b[0mnum_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_outputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2021-09-30/lib/python3.8/site-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     57\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0m\u001b[1;32m     60\u001b[0m                                         inputs, attrs, num_outputs)\n\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b88b057cf34efecd776605b6493619ffcb4d411e0887d16b1b551b502979a3a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}