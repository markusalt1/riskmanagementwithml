{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "#Results were produced in stints. This is the number of the last stint.\r\n",
    "run = 18"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.utils import shuffle\r\n",
    "from scipy import stats\r\n",
    "from scipy import optimize\r\n",
    "import joblib\r\n",
    "\r\n",
    "#folder for saving results\r\n",
    "filepath = \".../Resultate_final/PTF/IS/PTF_GlueVaR_IS_sim_saved/\""
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "#Market and option parameters as in section 4.2 of 'Assessing Asset-Liability Risk with Neural Networks' (Cheridito, Ery, Wüthrich 2020)\r\n",
    "s_0 = 100\r\n",
    "r = 0.01\r\n",
    "corr= 0.3\r\n",
    "tau = 1/52\r\n",
    "T = 1/3\r\n",
    "K = 100\r\n",
    "\r\n",
    "mu = np.empty(20)\r\n",
    "sigma = np.empty(20)\r\n",
    "for i in range(0,10):\r\n",
    "    mu[i] = mu[i+10] = (3+(i+1)/2)/100\r\n",
    "    sigma[i] = sigma[i+10] = (15+(i+1))/100\r\n",
    "\r\n",
    "cov_mat = np.empty((20,20))\r\n",
    "for i in range(0,20):\r\n",
    "    for j in range(0,20):\r\n",
    "        if i != j:\r\n",
    "            cov_mat[i,j] = corr\r\n",
    "        else:\r\n",
    "            cov_mat[i,j] = 1\r\n",
    "\r\n",
    "C = np.linalg.cholesky(cov_mat)\r\n",
    "\r\n",
    "#Confidence levels and parameters for GlueVaR\r\n",
    "alpha_Glue = 0.95\r\n",
    "beta_Glue = 0.995\r\n",
    "omega_Glue = np.array([1/3,1/3])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Sizes for training set, validation set, test set, and set size for Monte Carlo estimation of the risk measures\r\n",
    "M_1 = 1500000\r\n",
    "M_2 = 500000\r\n",
    "M_3 = 500000\r\n",
    "#ignore N or N_2 in the following. Was kept just in case, but not used.\r\n",
    "N_2 = 1\r\n",
    "M_MC = 500000\r\n",
    "#size of the set of data points used to calculate an IS density\r\n",
    "M_IS = 1000000\r\n",
    "#quantile for which the IS density will be computed\r\n",
    "alpha_IS = 0.975"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "source": [
    "#Function for calculating simulated values of S_tau and simulated payoffs P_T from simulations of multivariate standard normal random variables\r\n",
    "def data_gen(Z,V):\r\n",
    "    #correlating the independent components of Z\r\n",
    "    Z = np.transpose(np.matmul(C,np.transpose(Z)))\r\n",
    "    \r\n",
    "    #simulate S_tau under P\r\n",
    "    S_tau = np.empty((len(Z), 20))\r\n",
    "    for j in range(0,20):\r\n",
    "        S_tau[:,j] = s_0 * np.exp( (mu[j]-0.5*sigma[j]**2)*tau + np.sqrt(tau)*sigma[j]*Z[:,j] )\r\n",
    "\r\n",
    "    #simulate S_T given S_tau under Q\r\n",
    "    S_T = np.empty((len(Z),20))\r\n",
    "    for j in range(0,20):\r\n",
    "        S_T[:,j] = S_tau[:,j] * np.exp( (r-0.5*sigma[j]**2)*(T-tau) + np.sqrt(T-tau)*sigma[j]*V[:,j] )\r\n",
    "\r\n",
    "    #compute discounted option payoffs\r\n",
    "    P_T_pre =np.empty((len(S_T), 20))\r\n",
    "    for j in range(0,10):\r\n",
    "        P_T_pre[:,j] = np.exp(-r*(T-tau)) * np.maximum(S_T[:,j]-K,0)\r\n",
    "    for j in range(10,20):\r\n",
    "        P_T_pre[:,j] = np.exp(-r*(T-tau)) * np.maximum(K-S_T[:,j],0)\r\n",
    "    P_T = np.sum(P_T_pre, axis=1)\r\n",
    "    return S_tau,P_T\r\n",
    "\r\n",
    "#the function DT(Z,\\theta)\r\n",
    "def data_trans_IS(Z,IS):\r\n",
    "    res = np.empty((len(Z),20))\r\n",
    "    for j in range(20):\r\n",
    "        res[:,j] = Z[:,j]*np.sqrt(IS[20+j]) + IS[j]\r\n",
    "    return res\r\n",
    "\r\n",
    "#The density function of Z\r\n",
    "def f(y):\r\n",
    "    return stats.multivariate_normal.pdf(y, mean=np.full(20,0), cov=np.identity(20))\r\n",
    "\r\n",
    "#The density function of Z_\\theta (note that x is interpreted as theta, needed for the least-squares solver to work properly)\r\n",
    "def f_theta(y, x):\r\n",
    "    return stats.multivariate_normal.pdf(y, mean=x[0:20], cov=np.diag(x[20:40]), allow_singular=True)\r\n",
    "\r\n",
    "#This function describes the approximation of the expression inside the sum of m_2(theta)\r\n",
    "def g_q_alpha_hat_reweighted(x,L,q_alpha_hat):\r\n",
    "    return np.sqrt(f(y=L[:,0:20])/f_theta(y=L[:,0:20],x=x))*(L[:,-1]>q_alpha_hat)\r\n",
    "\r\n",
    "#bounds for the IS density parameters (for the parameters corresponding to the mean no bounds are necessary, the standard deviation parameters however needs to be non-negative)\r\n",
    "bnds_lower = np.empty((40))\r\n",
    "bnds_upper = np.empty((40))\r\n",
    "for j in range(20):\r\n",
    "    bnds_lower[j] = -np.inf\r\n",
    "    bnds_upper[j] = np.inf\r\n",
    "    bnds_lower[20+j] = 0\r\n",
    "    bnds_upper[20+j] = np.inf\r\n",
    "    \r\n",
    "bnds = (bnds_lower, bnds_upper)\r\n",
    "\r\n",
    "#function for calculating GlueVaR in an IS setting\r\n",
    "def GlueVaR_IS(omega, L, alpha, beta, w):\r\n",
    "    j_beta = 0\r\n",
    "    w_sum_tmp = 0\r\n",
    "    while(w_sum_tmp <= (1-beta)):\r\n",
    "        w_sum_tmp += w[j_beta]\r\n",
    "        j_beta += 1\r\n",
    "        \r\n",
    "    j_alpha = j_beta\r\n",
    "    while(w_sum_tmp <= (1-alpha)):\r\n",
    "        w_sum_tmp += w[j_alpha]\r\n",
    "        j_alpha += 1\r\n",
    "        \r\n",
    "    ES_beta = 1/(1-beta) * np.sum(w[0:j_beta-1]*L[0:j_beta-1]) + ( 1 - (1 / (1-beta)) * np.sum(w[0:j_beta-1]) )*L[j_beta]\r\n",
    "    ES_alpha = 1/(1-alpha) * np.sum(w[0:j_alpha-1]*L[0:j_alpha-1]) + ( 1 - (1 / (1-alpha)) * np.sum(w[0:j_alpha-1]) )*L[j_alpha]\r\n",
    "    VaR_alpha = L[j_alpha]\r\n",
    "\r\n",
    "    return omega[0]*ES_beta + omega[1]*ES_alpha + (1-omega[0]-omega[1])*VaR_alpha"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "source": [
    "for j in range(84):\r\n",
    "    #Generating realisations of multivariate standard normal random variables, V correlated\r\n",
    "    Z_IS = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_IS)\r\n",
    "    V_IS = np.random.multivariate_normal(mean=np.full(20,0), cov=cov_mat, size=M_IS)\r\n",
    "\r\n",
    "    #Calculate the risk factor S_tau and the corresponding simulated payoffs P_T\r\n",
    "    S_tau_IS, P_T_IS = data_gen(Z=Z_IS, V=V_IS)\r\n",
    "\r\n",
    "    #define and compile neural network model, setup as in 'Assessing Asset-Liability Risk with Neural Networks' (Cheridito, Ery, Wüthrich 2020)\r\n",
    "    bi_IS = np.log( np.sum(P_T_IS)/len(P_T_IS))\r\n",
    "    model_IS = tf.keras.models.Sequential([\r\n",
    "        tf.keras.layers.BatchNormalization(input_shape=(20,)),\r\n",
    "        tf.keras.layers.Dense(20, activation='tanh'),\r\n",
    "        tf.keras.layers.Dense(20, activation='tanh'),\r\n",
    "        tf.keras.layers.Dense(1, activation='exponential', bias_initializer=tf.keras.initializers.Constant(value=bi_IS))])\r\n",
    "    model_IS.compile(loss='mse', optimizer='adam', metrics=['mse'])\r\n",
    "    model_IS.fit(x=S_tau_IS, y=P_T_IS, epochs=100, batch_size=10000, verbose=0)\r\n",
    "\r\n",
    "    #Calculate realisations of L_hat from the training data set using the trained neural network\r\n",
    "    L_hat_IS = np.column_stack((Z_IS, model_IS.predict(S_tau_IS)[:,0]))\r\n",
    "    L_hat_IS_sort = L_hat_IS[L_hat_IS[:,-1].argsort()[::-1]]\r\n",
    "\r\n",
    "    #Calculating the corresponding estimator for Value-at-Risk in order to approximate g\r\n",
    "    q_alpha_IS_hat = L_hat_IS_sort[int(M_IS*(1-alpha_IS)-1), -1]\r\n",
    "    print('q_alpha_IS_hat_NN:',q_alpha_IS_hat)\r\n",
    "\r\n",
    "    #Calculating the (hopefully) approximately optimal \\theta^*_{NN} by minimising m_2 using the approximated g\r\n",
    "    IS_NN = optimize.least_squares(g_q_alpha_hat_reweighted, x0=np.concatenate((np.full(20,0),np.full(20,1))), args=(L_hat_IS, q_alpha_IS_hat), bounds=bnds).x\r\n",
    "\r\n",
    "    #define and train a random forest according to the optimal parameters from tuning\r\n",
    "    rfr_IS = RandomForestRegressor(n_estimators=160, criterion='squared_error', max_features=8, min_samples_leaf=70, bootstrap=True, verbose=0, n_jobs=-1)\r\n",
    "    rfr_IS.fit(X=S_tau_IS, y=P_T_IS)\r\n",
    "\r\n",
    "    #Calculate realisations of L_hat from the training data set using the trained random forest\r\n",
    "    L_hat_IS = np.column_stack((Z_IS, rfr_IS.predict(S_tau_IS)))\r\n",
    "    L_hat_IS_sort = L_hat_IS[L_hat_IS[:,-1].argsort()[::-1]]\r\n",
    "\r\n",
    "    #Calculating the corresponding estimator for Value-at-Risk in order to approximate g\r\n",
    "    q_alpha_IS_hat = L_hat_IS_sort[int(M_IS*(1-alpha_IS)-1), -1]\r\n",
    "    print('q_alpha_IS_hat_RF:',q_alpha_IS_hat)\r\n",
    "\r\n",
    "    #Calculating the (hopefully) approximately optimal \\theta^*_{RF} by minimising m_2 using the approximated g\r\n",
    "    IS_RF = optimize.least_squares(g_q_alpha_hat_reweighted, x0=np.concatenate((np.full(20,0),np.full(20,1))), args=(L_hat_IS, q_alpha_IS_hat),bounds=bnds).x\r\n",
    "\r\n",
    "    #print IS density parameters for checking\r\n",
    "    print('IS_NN:',IS_NN)\r\n",
    "    print('IS_RF:',IS_RF)\r\n",
    "    \r\n",
    "    #Generating simulations for multivariate standard normal random variables (uncorrelated for Z and correlated for V) for training set, validation set, test set, set for Monte Carlo estimation of risk measures\r\n",
    "    Z_train = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_1)\r\n",
    "    V_train = np.random.multivariate_normal(mean=np.full(20,0), cov=cov_mat, size=M_1)\r\n",
    "    Z_val = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_2)\r\n",
    "    V_val = np.random.multivariate_normal(mean=np.full(20,0), cov=cov_mat, size=M_2)\r\n",
    "    Z_test = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_3)\r\n",
    "    V_test = np.random.multivariate_normal(mean=np.full(20,0), cov=cov_mat, size=M_3)\r\n",
    "    Z_MC = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_MC)\r\n",
    "    V_MC = np.random.multivariate_normal(mean=np.full(20,0), cov=cov_mat, size=M_MC)\r\n",
    "\r\n",
    "    #calculate DT(Z,\\theta^*_{NN})\r\n",
    "    Z_train_NN = data_trans_IS(Z_train,IS_NN)\r\n",
    "    Z_val_NN = data_trans_IS(Z_val,IS_NN)\r\n",
    "    Z_test_NN = data_trans_IS(Z_test,IS_NN)\r\n",
    "    Z_MC_NN = data_trans_IS(Z_MC,IS_NN)\r\n",
    "    #calculating the risk factors under the IS distribution and corresponding option prices\r\n",
    "    S_tau_train_NN, P_T_train_NN = data_gen(Z=Z_train_NN, V=V_train)\r\n",
    "    S_tau_val_NN, P_T_val_NN = data_gen(Z=Z_val_NN, V=V_val)\r\n",
    "    S_tau_test_NN, P_T_test_NN = data_gen(Z=Z_test_NN, V=V_test)\r\n",
    "    S_tau_MC_NN, P_T_MC_NN = data_gen(Z=Z_MC_NN, V=V_MC)\r\n",
    "\r\n",
    "    #calculate DT(Z,\\theta^*_{RF})\r\n",
    "    Z_train_RF = data_trans_IS(Z_train,IS_RF)\r\n",
    "    Z_val_RF = data_trans_IS(Z_val,IS_RF)\r\n",
    "    Z_test_RF = data_trans_IS(Z_test,IS_RF)\r\n",
    "    Z_MC_RF = data_trans_IS(Z_MC,IS_RF)\r\n",
    "    #calculating the risk factors under the IS distribution and corresponding option prices\r\n",
    "    S_tau_train_RF, P_T_train_RF = data_gen(Z=Z_train_RF, V=V_train)\r\n",
    "    S_tau_val_RF, P_T_val_RF = data_gen(Z=Z_val_RF, V=V_val)\r\n",
    "    S_tau_test_RF, P_T_test_RF = data_gen(Z=Z_test_RF, V=V_test)\r\n",
    "    S_tau_MC_RF, P_T_MC_RF = data_gen(Z=Z_MC_RF, V=V_MC)\r\n",
    "    \r\n",
    "    #calculating parameters for the sets B_1 and B_2\r\n",
    "    s_20_1 = s_0 * np.exp((mu[0:3]-0.5*sigma[0:3]**2)*tau + sigma[0:3]*np.sqrt(tau)*stats.norm.ppf(0.2, loc=0, scale=1))\r\n",
    "    s_80_1 = s_0 * np.exp((mu[9:12]-0.5*sigma[9:12]**2)*tau + sigma[9:12]*np.sqrt(tau)*stats.norm.ppf(0.8, loc=0, scale=1))\r\n",
    "    s_20_2 = s_0 * np.exp((mu[9:12]-0.5*sigma[9:12]**2)*tau + sigma[9:12]*np.sqrt(tau)*stats.norm.ppf(0.2, loc=0, scale=1))\r\n",
    "    s_80_2 = s_0 * np.exp((mu[0:3]-0.5*sigma[0:3]**2)*tau + sigma[0:3]*np.sqrt(tau)*stats.norm.ppf(0.8, loc=0, scale=1))\r\n",
    "\r\n",
    "    #calculate the indices of the set B_1 and B_2 for the test set created with the IS density calculated by the neural network\r\n",
    "    B_1_NN = np.apply_along_axis(np.all, axis=1, arr=np.column_stack( (np.apply_along_axis(np.all, axis=1, arr=S_tau_test_NN[:,0:3] > s_20_1), np.apply_along_axis(np.all, axis=1, arr=S_tau_test_NN[:,9:12] < s_80_1)) ) )\r\n",
    "    B_2_NN = np.apply_along_axis(np.all, axis=1, arr=np.column_stack( (np.apply_along_axis(np.all, axis=1, arr=S_tau_test_NN[:,0:3] < s_80_2), np.apply_along_axis(np.all, axis=1, arr=S_tau_test_NN[:,9:12] > s_20_2)) ) )\r\n",
    "\r\n",
    "    #calculate the indices of the set B_1 and B_2 for the test set created with the IS density calculated by the random forest\r\n",
    "    B_1_RF = np.apply_along_axis(np.all, axis=1, arr=np.column_stack( (np.apply_along_axis(np.all, axis=1, arr=S_tau_test_RF[:,0:3] > s_20_1), np.apply_along_axis(np.all, axis=1, arr=S_tau_test_RF[:,9:12] < s_80_1)) ) )\r\n",
    "    B_2_RF = np.apply_along_axis(np.all, axis=1, arr=np.column_stack( (np.apply_along_axis(np.all, axis=1, arr=S_tau_test_RF[:,0:3] < s_80_2), np.apply_along_axis(np.all, axis=1, arr=S_tau_test_RF[:,9:12] > s_20_2)) ) )\r\n",
    "    \r\n",
    "    #define and compile neural network model, setup as in section 4.2 of 'Assessing Asset-Liability Risk with Neural Networks' (Cheridito, Ery, Wüthrich 2020)\r\n",
    "    bi = np.log( np.sum(P_T_train_NN)/len(P_T_train_NN))\r\n",
    "    model = tf.keras.models.Sequential([\r\n",
    "        tf.keras.layers.BatchNormalization(input_shape=(20,)),\r\n",
    "        tf.keras.layers.Dense(20, activation='tanh'),\r\n",
    "        tf.keras.layers.Dense(20, activation='tanh'),\r\n",
    "        tf.keras.layers.Dense(1, activation='exponential', bias_initializer=tf.keras.initializers.Constant(value=bi))])\r\n",
    "    model.compile(loss='mse', optimizer='adam', metrics=['mse'])\r\n",
    "    #training the neural network\r\n",
    "    hist = model.fit(x=S_tau_train_NN, y=P_T_train_NN, epochs=100, batch_size=10000, validation_data=(S_tau_val_NN,P_T_val_NN), verbose=0)\r\n",
    "    \r\n",
    "    #computation of the metrics (a), (b), (c) with B_1 and (c) with B_2 for the neural network\r\n",
    "    P_T_pred_NN = model.predict(S_tau_test_NN)[:,0]\r\n",
    "    mse_train_NN = hist.history['mse'][-1]\r\n",
    "    mse_val_NN = hist.history['val_mse'][-1]\r\n",
    "    mc_tmp = P_T_pred_NN - P_T_test_NN\r\n",
    "    metric_a_NN = np.sum(mc_tmp)/len(P_T_test_NN)\r\n",
    "    metric_b_NN = np.sum((mc_tmp)*P_T_pred_NN)/len(P_T_test_NN)\r\n",
    "    metric_c_B_1_NN = np.sum(mc_tmp[B_1_NN])/len(P_T_test_NN)\r\n",
    "    metric_c_B_2_NN = np.sum(mc_tmp[B_2_NN])/len(P_T_test_NN)\r\n",
    "\r\n",
    "    #computation of option price depending on the risk factor S_tau according to the models, i.e. computation of L_hat_i's\r\n",
    "    L_hat_NN = model.predict(S_tau_MC_NN)[:,0]\r\n",
    "    L_hat_c_NN = np.column_stack((Z_MC_NN, L_hat_NN))\r\n",
    "    \r\n",
    "    #calculation of the IS estimator for GlueVaR\r\n",
    "    L_hat_c_sort_NN = L_hat_c_NN[L_hat_c_NN[:,-1].argsort()[::-1]]\r\n",
    "    w = f(L_hat_c_sort_NN[:,0:20])/(M_MC*f_theta(x=IS_NN, y=L_hat_c_sort_NN[:,0:20]))\r\n",
    "\r\n",
    "    GlueVaR_hat_NN = GlueVaR_IS(omega=omega_Glue, alpha=alpha_Glue, beta=beta_Glue, L=L_hat_c_sort_NN[:,-1], w=w)\r\n",
    "    print('GlueVaR_hat_NN:',GlueVaR_hat_NN)\r\n",
    "    \r\n",
    "    \r\n",
    "    #perform a grid search in order to find the (approximately) best hyperparameter min_samples_leaf\r\n",
    "    #values that will be checked\r\n",
    "    max_features_list = [8]\r\n",
    "    min_samples_leaf_list = [30,40,50]\r\n",
    "    opt_param = np.full(2,0)\r\n",
    "    opt_score = np.inf\r\n",
    "\r\n",
    "    for max_features in max_features_list:\r\n",
    "        for min_samples_leaf in min_samples_leaf_list:\r\n",
    "            rfr_tuning = RandomForestRegressor(n_estimators=160, max_features=max_features, min_samples_leaf=min_samples_leaf, bootstrap=True, criterion='squared_error', verbose=0, n_jobs=-1)\r\n",
    "            rfr_tuning.fit(X=S_tau_train_RF, y=P_T_train_RF)\r\n",
    "            score = mean_squared_error(y_true=P_T_val_RF, y_pred=rfr_tuning.predict(S_tau_val_RF))\r\n",
    "            if score < opt_score:\r\n",
    "                opt_param_RF = np.array([max_features,min_samples_leaf])\r\n",
    "                opt_score = score\r\n",
    "    \r\n",
    "    #definition and training of random forest regressor\r\n",
    "    rfr = RandomForestRegressor(n_estimators=400, criterion='squared_error', max_features=int(opt_param_RF[0]), min_samples_leaf=int(opt_param_RF[1]), bootstrap=True, verbose=0, warm_start=True, n_jobs=-1)\r\n",
    "    rfr.fit(X=S_tau_train_RF, y=P_T_train_RF)\r\n",
    "    \r\n",
    "    #computation of the metrics (a), (b), (c) with B_1 and (c) with B_2 and training/valdiation MSE for the random forest\r\n",
    "    mse_train_RF = mean_squared_error(y_true=P_T_train_RF, y_pred=rfr.predict(S_tau_train_RF))\r\n",
    "    mse_val_RF = mean_squared_error(y_true=P_T_val_RF, y_pred=rfr.predict(S_tau_val_RF))\r\n",
    "    P_T_pred_RF = rfr.predict(S_tau_test_RF)\r\n",
    "    mc_tmp = P_T_pred_RF - P_T_test_RF\r\n",
    "    metric_a_RF = np.sum(mc_tmp)/len(P_T_test_RF)\r\n",
    "    metric_b_RF = np.sum((mc_tmp)*P_T_pred_RF)/len(P_T_test_RF)\r\n",
    "    metric_c_B_1_RF = np.sum(mc_tmp[B_1_RF])/len(P_T_test_RF)\r\n",
    "    metric_c_B_2_RF = np.sum(mc_tmp[B_2_RF])/len(P_T_test_RF)\r\n",
    "\r\n",
    "    #computation of option price depending on the risk factor S_tau according to the models, i.e. computation of L_hat_i's\r\n",
    "    L_hat_RF = rfr.predict(S_tau_MC_RF)\r\n",
    "    L_hat_c_RF = np.column_stack((Z_MC_RF, L_hat_RF))\r\n",
    "    \r\n",
    "    #calculation of the IS estimator for GlueVaR\r\n",
    "    L_hat_c_sort_RF = L_hat_c_RF[L_hat_c_RF[:,-1].argsort()[::-1]]\r\n",
    "    w = f(L_hat_c_sort_RF[:,0:20])/(M_MC*f_theta(x=IS_RF, y=L_hat_c_sort_RF[:,0:20]))\r\n",
    "\r\n",
    "    GlueVaR_hat_RF = GlueVaR_IS(omega=omega_Glue, alpha=alpha_Glue, beta=beta_Glue, L=L_hat_c_sort_RF[:,-1], w=w)\r\n",
    "    print('GlueVaR_hat_RF:',GlueVaR_hat_RF)\r\n",
    "    \r\n",
    "    #save results for further evaluation\r\n",
    "    output = np.array([[mse_train_NN,mse_val_NN,metric_a_NN,metric_b_NN,metric_c_B_1_NN,metric_c_B_2_NN,GlueVaR_hat_NN],\r\n",
    "                      [mse_train_RF,mse_val_RF,metric_a_RF,metric_b_RF,metric_c_B_1_RF,metric_c_B_2_RF,GlueVaR_hat_RF]])\r\n",
    "\r\n",
    "    joblib.dump(output,filepath+'output_'+str(run)+'_'+str(j)+'.joblib')\r\n",
    "    #since IS_NN and IS_RF are so high-dimensional we save them separately in order to avoid confusion in the later evaluation of results\r\n",
    "    joblib.dump(IS_NN, '.../Resultate_final/PTF/IS/PTF_GlueVaR_IS_sim_NN_densities_saved'+'output_'+str(run)+'_'+str(j)+'.joblib')\r\n",
    "    joblib.dump(IS_RF, '.../Resultate_final/PTF/IS/PTF_GlueVaR_IS_sim_RF_densities_saved'+'output_'+str(run)+'_'+str(j)+'.joblib')\r\n",
    "    #prints just for checking while the notebook is running\r\n",
    "    print(j)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "2021-11-02 08:29:13.231204: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-02 08:29:22.360990: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30988 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:89:00.0, compute capability: 7.0\n",
      "2021-11-02 08:29:22.505633: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 30988 MB memory:  -> device: 1, name: Tesla V100-SXM2-32GB, pci bus id: 0000:8a:00.0, compute capability: 7.0\n",
      "2021-11-02 08:29:22.507127: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:2 with 30988 MB memory:  -> device: 2, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b2:00.0, compute capability: 7.0\n",
      "2021-11-02 08:29:22.508609: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1510] Created device /job:localhost/replica:0/task:0/device:GPU:3 with 30988 MB memory:  -> device: 3, name: Tesla V100-SXM2-32GB, pci bus id: 0000:b3:00.0, compute capability: 7.0\n",
      "2021-11-02 08:29:25.603730: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "q_alpha_IS_hat_NN: 106.17752838134766\n",
      "q_alpha_IS_hat_RF: 103.84627197741202\n",
      "IS_NN: [ 0.6051087   0.48251951  0.41141153  0.36303101  0.26660014  0.31550745\n",
      "  0.33382513  0.29736673  0.32940314  0.26051545 -0.5771838  -0.51645149\n",
      " -0.48734866 -0.43134799 -0.53375663 -0.5385047  -0.46942758 -0.51557246\n",
      " -0.44182426 -0.38435013  1.22356739  1.11175308  1.09532571  1.0175937\n",
      "  1.04058145  1.03319843  1.02839632  1.02680196  1.00597196  1.02737916\n",
      "  1.04838831  1.0056936   0.967057    0.99636615  0.9852805   0.97291789\n",
      "  1.00631847  0.98437884  0.97580597  1.03483247]\n",
      "IS_RF: [ 0.53739023  0.42323774  0.36553309  0.29807422  0.27855108  0.24045673\n",
      "  0.30435357  0.2987091   0.30572052  0.31158499 -0.27960289 -0.30378144\n",
      " -0.27520534 -0.28428091 -0.30205689 -0.28591184 -0.2762694  -0.29930264\n",
      " -0.29264143 -0.29202497  1.29116776  1.16734988  1.10237859  1.10695457\n",
      "  1.11386559  1.05717862  1.06520218  1.02248105  1.01295523  1.05521698\n",
      "  1.0335196   1.0541283   1.02974319  1.03534416  1.0023337   1.03670326\n",
      "  1.02182655  1.02337658  1.02302294  1.03943615]\n",
      "GlueVaR_hat_NN: 107.46329544747435\n",
      "GlueVaR_hat_RF: 107.36565417380734\n",
      "0\n",
      "q_alpha_IS_hat_NN: 105.89398193359375\n",
      "q_alpha_IS_hat_RF: 103.8915104140192\n",
      "IS_NN: [ 0.6791149   0.52907848  0.44302367  0.38894946  0.34979643  0.29416687\n",
      "  0.31685859  0.26259634  0.31600609  0.28328008 -0.61132    -0.49576944\n",
      " -0.48304071 -0.46531949 -0.46995623 -0.49011449 -0.51990357 -0.36038674\n",
      " -0.42161449 -0.45784663  1.077088    1.08105751  1.06196657  1.03646604\n",
      "  1.03666126  1.01859295  1.01340491  0.98958788  1.01474803  1.03400139\n",
      "  0.96791959  1.01823507  1.03185391  0.95476204  0.9623666   0.96924587\n",
      "  0.97757604  0.97633908  0.98737102  0.98882372]\n",
      "IS_RF: [ 0.53003211  0.41287555  0.3454463   0.325113    0.28585217  0.28270225\n",
      "  0.2851102   0.26043538  0.29997621  0.28689137 -0.33957761 -0.30578527\n",
      " -0.27004943 -0.30401812 -0.28063034 -0.2762929  -0.30017847 -0.2609376\n",
      " -0.29054134 -0.28052398  1.26018305  1.12332813  1.14751871  1.05932283\n",
      "  1.09144727  1.05582548  1.05094195  1.02613999  1.03672476  1.06799502\n",
      "  1.04442725  1.01039118  1.05144572  0.98366887  1.00717106  1.02567405\n",
      "  1.0125484   1.00446528  1.04009739  1.00409073]\n",
      "GlueVaR_hat_NN: 108.11628007246975\n",
      "GlueVaR_hat_RF: 107.50409791619853\n",
      "1\n",
      "q_alpha_IS_hat_NN: 105.95323181152344\n",
      "q_alpha_IS_hat_RF: 104.18399558960118\n",
      "IS_NN: [ 0.71118809  0.53384946  0.40576299  0.39160755  0.25203691  0.34860612\n",
      "  0.26294223  0.35163329  0.35149296  0.2887936  -0.56667548 -0.50025094\n",
      " -0.50309453 -0.46899633 -0.43641318 -0.41127223 -0.49188768 -0.39725182\n",
      " -0.42906333 -0.41727546  1.17210724  1.08782849  1.09835296  1.00711387\n",
      "  1.06903504  1.03703218  1.05676968  1.04892936  1.02958653  1.04946899\n",
      "  0.99159575  0.99388675  1.0199077   0.98768491  0.99682419  0.99245337\n",
      "  1.01211188  1.00221824  0.98709687  1.03292987]\n",
      "IS_RF: [ 0.54172453  0.41541959  0.33008935  0.29842991  0.27159462  0.32754001\n",
      "  0.29031599  0.27422753  0.32797037  0.27653356 -0.29076769 -0.29757903\n",
      " -0.29637567 -0.28234376 -0.25423763 -0.27076342 -0.2707418  -0.25843931\n",
      " -0.26988228 -0.29047473  1.30175764  1.14308949  1.10549558  1.05296457\n",
      "  1.13865506  1.02830012  1.0662252   1.05529841  1.04804874  1.0745335\n",
      "  1.04780779  1.03243842  1.02489201  1.0228846   1.00317621  1.03324716\n",
      "  1.01756985  1.02851707  1.02143101  1.04243271]\n",
      "GlueVaR_hat_NN: 108.49977842136062\n",
      "GlueVaR_hat_RF: 107.44267777251571\n",
      "2\n",
      "q_alpha_IS_hat_NN: 105.60942077636719\n",
      "q_alpha_IS_hat_RF: 104.0547217500012\n",
      "IS_NN: [ 0.62660663  0.46201565  0.31729321  0.34853757  0.3396629   0.31539261\n",
      "  0.28823305  0.27506556  0.29942606  0.25781623 -0.51320883 -0.43923508\n",
      " -0.44212178 -0.38369785 -0.44738256 -0.41312556 -0.42826783 -0.3535236\n",
      " -0.43857368 -0.38606107  1.34717738  1.28248914  1.17388902  1.08688003\n",
      "  1.03506535  1.05280621  1.02871111  1.06422811  1.01344372  1.0431827\n",
      "  1.01362261  1.03505451  1.01395464  1.05111167  1.0161041   1.01990114\n",
      "  1.00095634  1.0229062   0.99253068  1.01672543]\n",
      "IS_RF: [ 0.52184911  0.38556093  0.30633566  0.27597011  0.29183519  0.28005409\n",
      "  0.2301314   0.27027632  0.24624146  0.25968543 -0.2905946  -0.25817309\n",
      " -0.24931946 -0.26425716 -0.2667678  -0.29343772 -0.25780863 -0.26178581\n",
      " -0.27120353 -0.26741976  1.39709901  1.26538159  1.13148969  1.1512262\n",
      "  1.09855599  1.08463264  1.08509743  1.09000758  1.03796286  1.02919735\n",
      "  1.0144532   1.02708903  1.04330061  1.04445309  1.0365359   1.02090933\n",
      "  1.01325729  1.01535648  0.99620691  0.99816986]\n",
      "GlueVaR_hat_NN: 108.5224494764785\n",
      "GlueVaR_hat_RF: 107.2507845685945\n",
      "3\n",
      "q_alpha_IS_hat_NN: 106.16883087158203\n",
      "q_alpha_IS_hat_RF: 104.0444957878199\n",
      "IS_NN: [ 0.50049893  0.34329259  0.35679779  0.29067248  0.27351055  0.19716417\n",
      "  0.22599566  0.21614042  0.30975444  0.30127842 -0.64541391 -0.60946009\n",
      " -0.53477919 -0.56488434 -0.56006914 -0.50839383 -0.50326879 -0.56189506\n",
      " -0.52140095 -0.51090593  1.22169197  1.17403111  1.08498902  1.08282536\n",
      "  1.01485699  1.03708464  1.04366719  1.02333581  1.02766715  1.00889002\n",
      "  0.94719246  0.98473843  0.99399685  0.96767195  0.96981697  0.98010182\n",
      "  0.96291022  0.97361508  1.04055039  0.968809  ]\n",
      "IS_RF: [ 0.57189472  0.40848018  0.39301946  0.29394909  0.27323924  0.27494505\n",
      "  0.2491759   0.27187489  0.3044519   0.31034717 -0.32519543 -0.27629939\n",
      " -0.26156569 -0.28217222 -0.28344806 -0.28953931 -0.30302541 -0.27707216\n",
      " -0.26881584 -0.27431044  1.30850257  1.1888675   1.10014487  1.0815043\n",
      "  1.10641662  1.03676505  1.03181032  1.05373778  1.02991584  1.02705535\n",
      "  1.01571372  1.03124457  1.04374497  1.02311006  1.02819285  1.00829491\n",
      "  1.01855722  1.03218896  1.04015786  1.04166935]\n",
      "GlueVaR_hat_NN: 108.27541171165373\n",
      "GlueVaR_hat_RF: 107.36272426903054\n",
      "4\n",
      "q_alpha_IS_hat_NN: 105.93620300292969\n",
      "q_alpha_IS_hat_RF: 104.121317168877\n",
      "IS_NN: [ 0.51247572  0.48682322  0.44255713  0.32362054  0.35319439  0.21589665\n",
      "  0.3613551   0.20315116  0.16005881  0.30235157 -0.51978222 -0.49459127\n",
      " -0.43740147 -0.45926132 -0.44418252 -0.43885111 -0.37201361 -0.51355295\n",
      " -0.48807017 -0.39676943  1.37952392  1.17061334  1.14828932  1.14091134\n",
      "  1.07127087  1.08103889  1.02976341  1.04651651  1.0616041   1.02178479\n",
      "  1.01858722  0.98627658  0.99863917  0.99176015  0.96789344  1.01237302\n",
      "  0.99428206  0.96767068  1.03078907  0.98846421]\n",
      "IS_RF: [ 0.55427297  0.38141445  0.35820174  0.3225184   0.2942578   0.27541654\n",
      "  0.29886929  0.27762257  0.21361488  0.27657387 -0.27590967 -0.25437008\n",
      " -0.24795493 -0.27935739 -0.2818836  -0.25543763 -0.27357688 -0.26086573\n",
      " -0.28389101 -0.26796628  1.34406185  1.25988232  1.13856498  1.15619311\n",
      "  1.07787424  1.10700877  1.09162728  1.07152637  1.04706797  1.03208357\n",
      "  1.04736919  1.01724154  1.02394935  1.03942524  1.00851147  1.03668186\n",
      "  1.01642202  1.00268234  1.04281137  1.02207845]\n",
      "GlueVaR_hat_NN: 106.92098564069505\n",
      "GlueVaR_hat_RF: 107.26319892499663\n",
      "5\n",
      "q_alpha_IS_hat_NN: 105.9457015991211\n",
      "q_alpha_IS_hat_RF: 103.91682530573098\n",
      "IS_NN: [ 0.60966792  0.56539951  0.42375327  0.30570193  0.37662631  0.14534532\n",
      "  0.265553    0.17442206  0.29055252  0.29101053 -0.5413327  -0.54051712\n",
      " -0.55138047 -0.50835978 -0.53469529 -0.51632609 -0.50898577 -0.44472164\n",
      " -0.43489531 -0.50367462  1.15540105  1.10638608  1.06363369  1.04741775\n",
      "  1.03498882  1.07149259  1.04144713  1.03771923  1.00072379  1.03718325\n",
      "  1.00148724  0.99895978  0.98971672  0.98783286  0.96151181  0.9601881\n",
      "  1.01970616  1.0006423   0.93819097  0.97654535]\n",
      "IS_RF: [ 0.53371315  0.4513963   0.38119906  0.32157465  0.25457762  0.3077362\n",
      "  0.27624646  0.24699117  0.29412191  0.29084385 -0.28997005 -0.29602286\n",
      " -0.28415045 -0.2632234  -0.29079465 -0.28142724 -0.29980303 -0.24727015\n",
      " -0.31174961 -0.30226242  1.3353383   1.15120899  1.13310329  1.09205556\n",
      "  1.06340397  1.06195024  1.04219406  1.01159282  1.00112872  1.02489086\n",
      "  1.02782801  1.05084182  1.02279772  1.02224939  1.01003649  1.00751659\n",
      "  1.02139729  1.01341104  0.99373041  1.03768633]\n",
      "GlueVaR_hat_NN: 107.89228720339428\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/scratch/slurm_tmpdir/job_20145443/ipykernel_3713478/4001799034.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    137\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[0mrfr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_estimators\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m400\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'squared_error'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_param_RF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmin_samples_leaf\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_param_RF\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbootstrap\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarm_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0mrfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mS_tau_train_RF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mP_T_train_RF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    141\u001b[0m     \u001b[0mmse_train_RF\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmean_squared_error\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mP_T_train_RF\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrfr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mS_tau_train_RF\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2021-09-30/lib/python3.8/site-packages/sklearn/ensemble/_forest.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    439\u001b[0m             \u001b[0;31m# parallel_backend contexts set at a higher level,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    440\u001b[0m             \u001b[0;31m# since correctness does not rely on using threads.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 441\u001b[0;31m             trees = Parallel(\n\u001b[0m\u001b[1;32m    442\u001b[0m                 \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    443\u001b[0m                 \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mverbose\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2021-09-30/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   1052\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1053\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1054\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1055\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1056\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/bwhpc/common/jupyter/tensorflow/2021-09-30/lib/python3.8/site-packages/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    931\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    932\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 933\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    934\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    935\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 762\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mready\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    764\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTimeoutError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.8/multiprocessing/pool.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    757\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    758\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 759\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_event\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    760\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    761\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    556\u001b[0m             \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_flag\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    557\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 558\u001b[0;31m                 \u001b[0msignaled\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_cond\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    559\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msignaled\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib64/python3.8/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    300\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m    \u001b[0;31m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 302\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}