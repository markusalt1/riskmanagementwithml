{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "source": [
    "import numpy as np\r\n",
    "import tensorflow as tf\r\n",
    "from sklearn.ensemble import RandomForestRegressor\r\n",
    "from sklearn.metrics import mean_squared_error\r\n",
    "from sklearn.utils import shuffle\r\n",
    "from scipy import stats\r\n",
    "from scipy import optimize\r\n",
    "import joblib\r\n",
    "import matplotlib.pyplot as plt"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "source": [
    "#Market and option parameters as in section 4.2 of 'Assessing Asset-Liability Risk with Neural Networks' (Cheridito, Ery, WÃ¼thrich 2020)\r\n",
    "s_0 = 100\r\n",
    "r = 0.01\r\n",
    "corr= 0.3\r\n",
    "tau = 1/52\r\n",
    "T = 1/3\r\n",
    "K = 100\r\n",
    "\r\n",
    "mu = np.empty(20)\r\n",
    "sigma = np.empty(20)\r\n",
    "for i in range(0,10):\r\n",
    "    mu[i] = mu[i+10] = (3+(i+1)/2)/100\r\n",
    "    sigma[i] = sigma[i+10] = (15+(i+1))/100\r\n",
    "\r\n",
    "cov_mat = np.empty((20,20))\r\n",
    "for i in range(0,20):\r\n",
    "    for j in range(0,20):\r\n",
    "        if i != j:\r\n",
    "            cov_mat[i,j] = corr\r\n",
    "        else:\r\n",
    "            cov_mat[i,j] = 1\r\n",
    "\r\n",
    "C = np.linalg.cholesky(cov_mat)\r\n",
    "\r\n",
    "#Confidence levels and parameters for GlueVaR\r\n",
    "alpha_Glue = 0.95\r\n",
    "beta_Glue = 0.995\r\n",
    "omega_Glue = np.array([1/3,1/3])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "source": [
    "M_MC = 10000000"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "source": [
    "#Function for calculating simulated values of S_tau and simulated payoffs P_T from simulations of multivariate standard normal random variables\r\n",
    "def data_gen(M,N,Z,V):\r\n",
    "    #correlating the independent components\r\n",
    "    Z = np.transpose(np.matmul(C,np.transpose(Z)))\r\n",
    "    V = np.transpose(np.matmul(C,np.transpose(V)))\r\n",
    "    \r\n",
    "    #simulate S_tau under P\r\n",
    "    S_tau_pre = np.empty((M, 20))\r\n",
    "    for j in range(0,20):\r\n",
    "        S_tau_pre[:,j] = s_0 * np.exp( (mu[j]-0.5*sigma[j]**2)*tau + np.sqrt(tau)*sigma[j]*Z[:,j] )\r\n",
    "    S_tau = np.tile(S_tau_pre, (N,1))\r\n",
    "\r\n",
    "    #simulate S_T under Q\r\n",
    "    S_T = np.empty((N*M,20))\r\n",
    "    for j in range(0,20):\r\n",
    "        S_T[:,j] = S_tau[:,j] * np.exp( (r-0.5*sigma[j]**2)*(T-tau) + np.sqrt(T-tau)*sigma[j]*V[:,j] )\r\n",
    "\r\n",
    "    #compute discounted option payoffs\r\n",
    "    P_T_pre =np.empty((len(S_T), 20))\r\n",
    "    for j in range(0,10):\r\n",
    "        P_T_pre[:,j] = np.exp(-r*(T-tau)) * np.maximum(S_T[:,j]-K,0)\r\n",
    "    for j in range(10,20):\r\n",
    "        P_T_pre[:,j] = np.exp(-r*(T-tau)) * np.maximum(K-S_T[:,j],0)\r\n",
    "    P_T = np.sum(P_T_pre, axis=1)\r\n",
    "    return S_tau,P_T\r\n",
    "\r\n",
    "#the function DT(Z,\\theta)\r\n",
    "def data_trans_IS(Z,IS):\r\n",
    "    res = np.empty((len(Z),20))\r\n",
    "    for j in range(20):\r\n",
    "        res[:,j] = Z[:,j]*np.sqrt(IS[20+j]) + IS[j]\r\n",
    "    return res\r\n",
    "\r\n",
    "#The density function corresponding to the physical probability measure P\r\n",
    "def f(y):\r\n",
    "    return stats.multivariate_normal.pdf(y, mean=np.full(20,0), cov=np.identity(20))\r\n",
    "\r\n",
    "#The density function corresponding to the IS probability measure (note that x is interpreted as theta, needed for the least-squares solver to work properly)\r\n",
    "def f_theta(y, x):\r\n",
    "    return stats.multivariate_normal.pdf(y, mean=x[0:20], cov=np.diag(x[20:40]), allow_singular=True)\r\n",
    "\r\n",
    "#Put and Call Black-Scholes Formulas\r\n",
    "def d1(K, t, x, sigma, r):\r\n",
    "    return (np.log(x/K)+(r+0.5*sigma**2)*t)/(sigma*np.sqrt(t))\r\n",
    "\r\n",
    "def d2(K, t, x, sigma, r):\r\n",
    "    return (np.log(x/K)+(r-0.5*sigma**2)*t)/(sigma*np.sqrt(t))\r\n",
    "\r\n",
    "def put_true(K, t, x, sigma, r): \r\n",
    "    return K*np.exp(-r*t)*stats.norm.cdf(-d2(K,t,x,sigma,r)) - x*stats.norm.cdf(-d1(K,t,x,sigma,r))\r\n",
    "\r\n",
    "def call_true(K, t, x, sigma, r):\r\n",
    "    return x*stats.norm.cdf(d1(K,t,x,sigma,r)) - K*np.exp(-r*t)*stats.norm.cdf(d2(K,t,x,sigma,r))\r\n",
    "\r\n",
    "#the true function l\r\n",
    "def P_T_true(x):\r\n",
    "    P_T = np.empty((len(x),20))\r\n",
    "    for j in range(0,10):\r\n",
    "        P_T[:,j] = call_true(K=100, t=(T-tau), x=x[:,j], sigma=sigma[j], r=r)\r\n",
    "        P_T[:,j+10] = put_true(K=100, t=(T-tau), x=x[:,j+10], sigma=sigma[j+10], r=r)\r\n",
    "    return np.sum(P_T, axis=1)\r\n",
    "\r\n",
    "#This function describes the approximation of the expression inside the sum of m_2(theta)\r\n",
    "def g_q_alpha_hat_reweighted(x,L,q_alpha_hat):\r\n",
    "    return np.sqrt(f(y=L[:,0:20])/f_theta(y=L[:,0:20],x=x))*(L[:,-1]>q_alpha_hat)\r\n",
    "\r\n",
    "#bounds for the IS density parameters (for the parameters corresponding to the mean no bounds are necessary, the standard deviation parameters however needs to be non-negative)\r\n",
    "bnds_lower = np.empty((40))\r\n",
    "bnds_upper = np.empty((40))\r\n",
    "for j in range(20):\r\n",
    "    bnds_lower[j] = -np.inf\r\n",
    "    bnds_upper[j] = np.inf\r\n",
    "    bnds_lower[20+j] = 0\r\n",
    "    bnds_upper[20+j] = np.inf\r\n",
    "    \r\n",
    "bnds = (bnds_lower, bnds_upper)\r\n",
    "\r\n",
    "#function for calculating GlueVaR\r\n",
    "def GlueVaR(omega, L, alpha, beta):\r\n",
    "    j_beta = int(len(L)*(1-beta))-1\r\n",
    "    j_alpha = int(len(L)*(1-alpha))-1\r\n",
    "\r\n",
    "    ES_beta = 1/(1-beta) * np.sum(L[0:j_beta-1])/len(L) + ( 1 - (j_beta-1)/((1-beta)*len(L)) )*L[j_beta]\r\n",
    "    ES_alpha = 1/(1-alpha) * np.sum(L[0:j_alpha-1])/len(L) + ( 1 - (j_alpha-1)/((1-alpha)*len(L)) )*L[j_alpha]\r\n",
    "    VaR_alpha = L[j_alpha]\r\n",
    "\r\n",
    "    return omega[0]*ES_beta + omega[1]*ES_alpha + (1-omega[0]-omega[1])*VaR_alpha"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "source": [
    "#Generating realisations of standard normal random variables\r\n",
    "Z = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_MC)\r\n",
    "V = np.random.multivariate_normal(mean=np.full(20,0), cov=np.identity(20), size=M_MC)\r\n",
    "\r\n",
    "#Calculate the risk factor S_tau and the corresponding simulated payoffs P_T\r\n",
    "S_tau, P_T = data_gen(M=M_MC, N=1, Z=Z, V=V)\r\n",
    "\r\n",
    "#Calculate realisations of L_hat from the training data set using the trained neural network\r\n",
    "L_hat = np.column_stack((Z, P_T_true(S_tau)))\r\n",
    "L_hat_sort = L_hat[L_hat[:,-1].argsort()[::-1]]\r\n",
    "\r\n",
    "#calculating GlueVaR estimator\r\n",
    "GlueVaR_hat = GlueVaR(omega=omega_Glue, L=L_hat_sort[:,-1], alpha=alpha_Glue, beta=beta_Glue)\r\n",
    "\r\n",
    "#reference value\r\n",
    "print(GlueVaR_hat)"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "107.80585242434293\n"
     ]
    }
   ],
   "metadata": {}
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "5b88b057cf34efecd776605b6493619ffcb4d411e0887d16b1b551b502979a3a"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}